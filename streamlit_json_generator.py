import io
import re
import json
import zipfile
from typing import Dict, Any, List, Tuple
from dataclasses import dataclass

import pandas as pd
import streamlit as st

# ------------------------
# CONFIG & CONSTANTS
# ------------------------
st.set_page_config(page_title="JSON Generator & Updater", layout="centered")

@dataclass
class ExcelColumns:
    """Define expected Excel column structures"""
    SINGLE_PLAN = ["service_id", "service_name"]
    MULTI_PLAN = ["json_name", "json_id", "service_id", "service_name"]
    SWAP_OFFER = ["tariff_id"]
    CATEGORY = ["offer_id", "category_id"]

# ------------------------
# UTILITY FUNCTIONS
# ------------------------
def safe_name(n: str) -> str:
    """Sanitize string for filename usage"""
    if not isinstance(n, str):
        n = str(n)
    s = re.sub(r"\s+", "_", n.strip())
    s = re.sub(r"[^0-9A-Za-z_\-\u0400-\u04FF]", "", s)
    return s or "file"

def validate_excel_columns(df: pd.DataFrame, expected_count: int, mode: str) -> Tuple[bool, str]:
    """Validate Excel file structure"""
    if df.empty:
        return False, "Excel —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π"
    
    if len(df.columns) < expected_count:
        return False, f"–û–∂–∏–¥–∞–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {expected_count} –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Ä–µ–∂–∏–º–∞ '{mode}'"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–≤—ã–µ N –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ
    if df.iloc[:, :expected_count].isnull().all().any():
        return False, "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—É—Å—Ç—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏"
    
    return True, ""

def remove_duplicates(df: pd.DataFrame, subset_cols: List[int]) -> Tuple[pd.DataFrame, int]:
    """Remove duplicate rows based on specified columns"""
    initial_count = len(df)
    cols_to_check = [df.columns[i] for i in subset_cols if i < len(df.columns)]
    df_cleaned = df.drop_duplicates(subset=cols_to_check, keep='first')
    duplicates_count = initial_count - len(df_cleaned)
    return df_cleaned, duplicates_count

def create_offering(service_id: str, service_name: str = None, locale: str = "en-US", 
                   expired: bool = False, include_name: bool = True) -> Dict[str, Any]:
    """Create a service offering object"""
    offering = {
        "expiredForSales": expired,
        "id": str(service_id),
        "isBundle": False,
    }
    if service_name and include_name:
        offering["name"] = [{"locale": locale, "value": str(service_name)}]
    return offering

def create_category_json(offer_id: str, category_id: str) -> Dict[str, Any]:
    """Create category JSON structure"""
    return {
        "id": str(offer_id),
        "category": [str(category_id)],
        "categoryRef": [
            {
                "id": str(category_id)
            }
        ]
    }

def build_json(name: str, uid: str, locale: str, offerings: List[Dict[str, Any]], 
               purpose: str = "addOn") -> Dict[str, Any]:
    """Build complete JSON structure"""
    json_obj = {
        "effective": True,
        "externalId": [],
        "localizedName": [{"locale": locale, "value": name}],
        "name": safe_name(name),
        "policy": [],
        "productOfferingsInGroup": offerings,
        "restriction": [],
        "id": str(uid),
    }
    
    if purpose == "addOn":
        json_obj["purpose"] = ["addOn"]
    elif purpose == "replaceOffer":
        json_obj["purpose"] = ["replaceOffer"]
        json_obj["description"] = [{"locale": locale, "value": name}]
    
    return json_obj

def create_zip_buffer(json_obj: Dict[str, Any], file_id: str, folder: str = "productOfferingGroup") -> io.BytesIO:
    """Create ZIP buffer with JSON file"""
    zip_buffer = io.BytesIO()
    pretty_json = json.dumps(json_obj, ensure_ascii=False, indent=4)
    
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr(f"{folder}/{safe_name(file_id)}.json", pretty_json)
    
    zip_buffer.seek(0)
    return zip_buffer

# ------------------------
# MODULE 1: UPDATE SERVICE (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤/–ø—Ä–æ–≤–µ—Ä–∫–∏)
# ------------------------
def update_zip_with_service(zip_file: zipfile.ZipFile, new_service: Dict[str, Any]) -> Tuple[Dict, Dict]:
    """Update all JSON files in ZIP with new service"""
    file_list = zip_file.namelist()
    json_files = [f for f in file_list if f.lower().endswith(".json") 
                  and "productofferinggroup/" in f.lower()]

    if not json_files:
        raise ValueError("JSON —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ productOfferingGroup/")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã (–Ω–µ —Ç–æ–ª—å–∫–æ JSON), —á—Ç–æ–±—ã –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å
    original_structure = {name: zip_file.open(name).read() for name in file_list}
    updated_jsons = {}

    for json_filename in json_files:
        try:
            raw = original_structure[json_filename]
            json_data = json.loads(raw.decode("utf-8"))
            
            if "productOfferingsInGroup" not in json_data or not isinstance(json_data["productOfferingsInGroup"], list):
                st.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω: –Ω–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ productOfferingsInGroup ‚Üí {json_filename}")
                continue

            existing_ids = {str(item.get("id")) for item in json_data["productOfferingsInGroup"]}
            if str(new_service.get("id")) in existing_ids:
                st.info(f"–£—Å–ª—É–≥–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ {json_filename}")
                continue

            json_data["productOfferingsInGroup"].append(new_service)
            updated_jsons[json_filename] = json.dumps(json_data, ensure_ascii=False, indent=4)
            
        except json.JSONDecodeError as e:
            st.warning(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON ({json_filename}): {e}")
            continue
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {json_filename}: {e}")
            continue

    return updated_jsons, original_structure

# ------------------------
# MODULE 1.5: EXPIRE + ADD (–ø–µ—Ä–µ–ø–∏—Å–∞–Ω–æ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏)
# ------------------------
def process_expire_and_add_services(
    uploaded_zip: bytes,
    expire_excel: bytes,
    add_excel: bytes,
    locale: str = "en-US"
) -> Tuple[io.BytesIO, Dict[str, Any]]:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç ZIP –∞—Ä—Ö–∏–≤:
    1) –≠–∫—Å–ø–∞–π—Ä–∏—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–µ —É—Å–ª—É–≥–∏ –ø–æ Excel (2 –∫–æ–ª–æ–Ω–∫–∏)
    2) –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —É—Å–ª—É–≥–∏ –ø–æ Excel (3 –∫–æ–ª–æ–Ω–∫–∏)
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—é–±—ã–µ –ø—Ä–æ—á–∏–µ —Ñ–∞–π–ª—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ ZIP –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    """

    # --- –ó–∞–≥—Ä—É–∂–∞–µ–º ZIP –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï —Ñ–∞–π–ª—ã ---
    zbuf = io.BytesIO(uploaded_zip)
    with zipfile.ZipFile(zbuf, "r") as zf:
        all_names = zf.namelist()
        if not all_names:
            raise ValueError("–ü—É—Å—Ç–æ–π ZIP –∞—Ä—Ö–∏–≤")
        all_bytes = {name: zf.read(name) for name in all_names}

    json_files = [
        n for n in all_names
        if n.lower().endswith(".json") and "productofferinggroup/" in n.lower()
    ]
    if not json_files:
        raise ValueError("–í ZIP –Ω–µ –Ω–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ productOfferingGroup/")

    # --- –ß–∏—Ç–∞–µ–º Excel-—Ñ–∞–π–ª—ã –∏–∑ bytes —á–µ—Ä–µ–∑ BytesIO ---
    df_expire = pd.read_excel(io.BytesIO(expire_excel), engine="openpyxl")
    df_add = pd.read_excel(io.BytesIO(add_excel), engine="openpyxl")

    # --- –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º ---
    if df_expire.shape[1] < 2:
        raise ValueError("Excel –¥–ª—è —ç–∫—Å–ø–∞–π—Ä–∞ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2 –∫–æ–ª–æ–Ω–∫–∏: json_id | service_id")
    if df_add.shape[1] < 3:
        raise ValueError("Excel –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 3 –∫–æ–ª–æ–Ω–∫–∏: json_id | service_name | service_id")

    df_expire = df_expire.iloc[:, :2]
    df_expire.columns = ["json_id", "service_id"]
    df_expire = df_expire.dropna(subset=["json_id", "service_id"]).assign(
        json_id=lambda d: d["json_id"].astype(str).str.strip(),
        service_id=lambda d: d["service_id"].astype(str).str.strip()
    )
    df_expire = df_expire[(df_expire["json_id"] != "") & (df_expire["service_id"] != "")]

    df_add = df_add.iloc[:, :3]
    df_add.columns = ["json_id", "service_name", "service_id"]
    df_add = df_add.dropna(subset=["json_id", "service_name", "service_id"]).assign(
        json_id=lambda d: d["json_id"].astype(str).str.strip(),
        service_id=lambda d: d["service_id"].astype(str).str.strip(),
        service_name=lambda d: d["service_name"].astype(str).str.strip()
    )
    # –£–¥–∞–ª—è–µ–º —è–≤–Ω—ã–µ –º—É—Å–æ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    df_add = df_add[
        (df_add["json_id"] != "") &
        (df_add["service_id"] != "") &
        (df_add["service_id"].str.lower() != "nan")
    ]

    # --- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ ---
    expire_map: Dict[str, List[str]] = df_expire.groupby("json_id")["service_id"].apply(list).to_dict()
    add_map: Dict[str, List[Dict[str, str]]] = df_add.groupby("json_id")[["service_name", "service_id"]].apply(
        lambda x: x.to_dict("records")
    ).to_dict()

    updated_jsons: Dict[str, str] = {}
    stats = {
        "files_processed": 0,
        "expired": 0,
        "already_expired": 0,
        "added": 0,
        "skipped_existing": 0
    }

    # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ JSON —Ñ–∞–π–ª–æ–≤ ---
    for filename in json_files:
        data = all_bytes[filename]
        try:
            json_data = json.loads(data.decode("utf-8"))
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filename}: {e}")
            continue

        json_id = str(json_data.get("id", "")).strip()
        if not json_id:
            stats["files_processed"] += 1
            continue

        offerings = json_data.get("productOfferingsInGroup")
        if not isinstance(offerings, list):
            offerings = []

        modified = False

        # 1) –≠–∫—Å–ø–∞–π—Ä —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —É—Å–ª—É–≥
        for sid in expire_map.get(json_id, []):
            sid = str(sid)
            for item in offerings:
                if str(item.get("id")) == sid:
                    if not item.get("expiredForSales", False):
                        item["expiredForSales"] = True
                        stats["expired"] += 1
                        modified = True
                    else:
                        stats["already_expired"] += 1

        # 2) –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —É—Å–ª—É–≥
        existing_ids = {str(o.get("id")) for o in offerings}
        for rec in add_map.get(json_id, []):
            nid = str(rec.get("service_id", "")).strip()
            nname = str(rec.get("service_name", "")).strip()
            if not nid or nid.lower() == "nan":
                continue
            if nid in existing_ids:
                stats["skipped_existing"] += 1
                continue
            offerings.append({
                "expiredForSales": False,
                "id": nid,
                "isBundle": False,
                "name": [{"locale": locale, "value": nname}]
            })
            existing_ids.add(nid)
            stats["added"] += 1
            modified = True

        # 3) –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        if modified:
            json_data["productOfferingsInGroup"] = offerings
            updated_jsons[filename] = json.dumps(json_data, ensure_ascii=False, indent=4)

        stats["files_processed"] += 1

    # --- –°–±–æ—Ä–∫–∞ –Ω–æ–≤–æ–≥–æ ZIP: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï —Ñ–∞–π–ª—ã, –º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ JSON ---
    out = io.BytesIO()
    with zipfile.ZipFile(out, "w", zipfile.ZIP_DEFLATED) as znew:
        for name in all_names:
            if name in updated_jsons:
                znew.writestr(name, updated_jsons[name])
            else:
                znew.writestr(name, all_bytes[name])
    out.seek(0)

    return out, stats

# ------------------------
# UI: NAVIGATION
# ------------------------
st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
page = st.sidebar.radio(
    "–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
    [
        "–î–æ–±–∞–≤–∏—Ç—å —É—Å–ª—É–≥—É –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞—Ä–∏—Ñ–Ω—ã–µ –ø–ª–∞–Ω—ã",
        "ADD NEW AND EXPIRE OLD AddOns",
        "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ JSON",
    ],
)

# =======================================================
# MODULE 1 UI: ADD SERVICE TO EXISTING ZIP
# =======================================================
if page == "–î–æ–±–∞–≤–∏—Ç—å —É—Å–ª—É–≥—É –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞—Ä–∏—Ñ–Ω—ã–µ –ø–ª–∞–Ω—ã":
    st.title("–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π —É—Å–ª—É–≥–∏ –≤ AddOn JSON —Ñ–∞–π–ª—ã")
    
    with st.form("update_form"):
        uploaded_zip = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤", type=["zip"])
        
        col1, col2 = st.columns(2)
        with col1:
            service_id = st.text_input("ID —É—Å–ª—É–≥–∏", 
                                      placeholder="ee1374db-4a25-4ae7-b78a-aa493a288f9f")
        with col2:
            expired_for_sales = st.selectbox("expiredForSales", [False, True], 
                                            format_func=lambda x: "false" if not x else "true")
        
        service_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏", 
                                    placeholder="4G Bonus 5GB BEEPUL")
        
        submitted = st.form_submit_button("–î–æ–±–∞–≤–∏—Ç—å —É—Å–ª—É–≥—É", type="primary")

    if submitted:
        errors = []
        if not uploaded_zip:
            errors.append("–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP –∞—Ä—Ö–∏–≤.")
        if not service_id.strip():
            errors.append("–í–≤–µ–¥–∏—Ç–µ ID —É—Å–ª—É–≥–∏.")
        if not service_name.strip():
            errors.append("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏.")

        if errors:
            for e in errors:
                st.error(e)
            st.stop()

        try:
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ ZIP –∞—Ä—Ö–∏–≤–∞..."):
                zip_buffer = io.BytesIO(uploaded_zip.read())
                
                with zipfile.ZipFile(zip_buffer, "r") as zip_file:
                    new_service = create_offering(service_id.strip(), service_name.strip(), 
                                                 expired=expired_for_sales)
                    updated_jsons, original_structure = update_zip_with_service(zip_file, new_service)

            if not updated_jsons:
                st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ JSON –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–ª–∏ –≤—Å–µ —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∞–Ω–Ω—É—é —É—Å–ª—É–≥—É.")
                st.stop()

            st.success(f"–£—Å–ª—É–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ {len(updated_jsons)} JSON —Ñ–∞–π–ª–æ–≤")

            first_file, first_json = next(iter(updated_jsons.items()))
            with st.expander(f"–ü—Ä–∏–º–µ—Ä –æ–±–Ω–æ–≤–ª—ë–Ω–Ω–æ–≥–æ JSON ({first_file})"):
                st.code(first_json, language="json")

            new_zip_buffer = io.BytesIO()
            with zipfile.ZipFile(new_zip_buffer, "w", zipfile.ZIP_DEFLATED) as new_zip:
                for name, data in original_structure.items():
                    if name in updated_jsons:
                        data = updated_jsons[name].encode("utf-8")
                    new_zip.writestr(name, data)

            new_zip_buffer.seek(0)
            new_zip_filename = uploaded_zip.name.replace(".zip", "_updated.zip")

            st.download_button(
                "–°–∫–∞—á–∞—Ç—å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π ZIP",
                new_zip_buffer,
                new_zip_filename,
                "application/zip",
                type="primary"
            )

        except zipfile.BadZipFile:
            st.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º ZIP –∞—Ä—Ö–∏–≤–æ–º")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")
            with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                st.exception(e)

# =======================================================
# MODULE 1.5 UI: EXPIRE AND ADD SERVICE (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)
# =======================================================
elif page == "ADD NEW AND EXPIRE OLD AddOns":
    st.title("–≠–∫—Å–ø–∞–π—Ä –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ AddOns —Å –ø–æ–º–æ—â—å—é Excel")

    st.markdown("""
    ### üß© –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
    1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ ZIP** —Å JSON-—Ñ–∞–π–ª–∞–º–∏ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ `productOfferingGroup/...json`)  
    2. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –¥–ª—è —ç–∫—Å–ø–∞–π—Ä–∞** ‚Äî 2 –∫–æ–ª–æ–Ω–∫–∏:
       - `json_id` ‚Üí ID POG   
       - `service_id` ‚Üí ID —É—Å–ª—É–≥–∏, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –∑–∞—ç–∫—Å–ø–∞–π—Ä–∏—Ç—å (–∑–Ω–∞—á–µ–Ω–∏–µ expired: `true`)
    3. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö —É—Å–ª—É–≥** ‚Äî 3 –∫–æ–ª–æ–Ω–∫–∏:
       - `POG ID` ‚Üí POG , –∫—É–¥–∞ –¥–æ–±–∞–≤–∏—Ç—å
       - `name` ‚Üí –∏–º—è –Ω–æ–≤–æ–π —É—Å–ª—É–≥–∏
       - `id` ‚Üí –µ—ë —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID  
    4. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É **–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É**
    """)

    uploaded_zip = st.file_uploader("üì¶ ZIP –∞—Ä—Ö–∏–≤ —Å JSON —Ñ–∞–π–ª–∞–º–∏", type=["zip"], key="expire_add_zip")
    excel_expire = st.file_uploader("üìò Excel –¥–ª—è —ç–∫—Å–ø–∞–π—Ä–∞ (2 –∫–æ–ª–æ–Ω–∫–∏)", type=["xls", "xlsx"])
    excel_add = st.file_uploader("üìó Excel –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö —É—Å–ª—É–≥ (3 –∫–æ–ª–æ–Ω–∫–∏)", type=["xls", "xlsx"])
    locale = st.text_input("üåê –Ø–∑—ã–∫ (locale)", value="en-US")

    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
        if not uploaded_zip or not excel_expire or not excel_add:
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ —Ç—Ä–∏ —Ñ–∞–π–ª–∞.")
            st.stop()

        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ ZIP –∞—Ä—Ö–∏–≤–∞..."):
            try:
                new_zip, stats = process_expire_and_add_services(
                    uploaded_zip.read(),
                    excel_expire.read(),
                    excel_add.read(),
                    locale
                )

                st.success("‚úÖ ZIP —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω!")

                col1, col2, col3, col4 = st.columns(4)
                col1.metric("–§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ", stats["files_processed"])
                col2.metric("–≠–∫—Å–ø–∞–π—Ä–µ–Ω–æ —É—Å–ª—É–≥", stats["expired"])
                col3.metric("–î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö", stats["added"])
                col4.metric("–ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∏)", stats["skipped_existing"])

                if stats.get("already_expired", 0) > 0:
                    st.caption(f"–£–∂–µ –±—ã–ª–∏ —ç–∫—Å–ø–∞–π—Ä–µ–Ω—ã: {stats['already_expired']}")

                st.download_button(
                    "üì• –°–∫–∞—á–∞—Ç—å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π ZIP",
                    new_zip,
                    "updated_addons.zip",
                    "application/zip",
                    type="primary"
                )

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")
                with st.expander("–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏"):
                    st.exception(e)

# =======================================================
# MODULE 2 UI: GENERATE NEW JSON FILES
# =======================================================
else:
    st.title("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä JSON ZIP —Ñ–∞–π–ª–æ–≤")
    
    subpage = st.radio(
        "–†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:",
        [
            "–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É—Å–ª—É–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–Ω–æ–≥–æ –ø–ª–∞–Ω–∞",
            "–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É—Å–ª—É–≥ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤",
            "Swap Offer (–ø–µ—Ä–µ—Ö–æ–¥—ã —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤)",
            "–ò–∑–º–µ–Ω–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ProductOfferingCategory",
        ],
    )

    # ===== SINGLE PLAN MODE =====
    if subpage == "–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É—Å–ª—É–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–Ω–æ–≥–æ –ø–ª–∞–Ω–∞":
        st.subheader("–û–¥–∏–Ω —Ç–∞—Ä–∏—Ñ–Ω—ã–π –ø–ª–∞–Ω")
        
        col1, col2 = st.columns(2)
        with col1:
            name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏")
            uid = st.text_input("ID —É—Å–ª—É–≥–∏")
        with col2:
            locale_gen = st.text_input("Language", value="en-US")
        
        file = st.file_uploader("Excel —Ñ–∞–π–ª (2 –∫–æ–ª–æ–Ω–∫–∏: ID —É—Å–ª—É–≥–∏, –ù–∞–∑–≤–∞–Ω–∏–µ)", type=["xls", "xlsx"])
        
        st.info("Excel –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2 –∫–æ–ª–æ–Ω–∫–∏: ID —É—Å–ª—É–≥–∏ | –ù–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏")
        
        if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", type="primary") and file:
            try:
                with st.spinner("–ß—Ç–µ–Ω–∏–µ Excel —Ñ–∞–π–ª–∞..."):
                    df = pd.read_excel(file, engine="openpyxl")
                
                is_valid, error_msg = validate_excel_columns(df, 2, "single plan")
                if not is_valid:
                    st.error(error_msg)
                    st.stop()
                
                df_cleaned, duplicates_count = remove_duplicates(df, [0])
                if duplicates_count > 0:
                    st.info(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}")
                
                id_col, name_col = df_cleaned.columns[0], df_cleaned.columns[1]
                offerings = [
                    create_offering(r[id_col], r[name_col], locale_gen) 
                    for _, r in df_cleaned.iterrows() 
                    if pd.notna(r[id_col])
                ]
                
                if not offerings:
                    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —É—Å–ª—É–≥ –≤ Excel —Ñ–∞–π–ª–µ")
                    st.stop()
                
                if not name.strip() or not uid.strip():
                    st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ '–ù–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏' –∏ 'ID —É—Å–ª—É–≥–∏' –¥–ª—è JSON.")
                    st.stop()

                final = build_json(name, uid, locale_gen, offerings, purpose="addOn")
                
                st.success(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(offerings)} —É—Å–ª—É–≥")
                with st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä JSON"):
                    st.json(final)
                
                zip_buffer = create_zip_buffer(final, uid)
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å ZIP",
                    zip_buffer,
                    f"{safe_name(name)}.zip",
                    "application/zip",
                    type="primary"
                )
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")
                with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                    st.exception(e)

    # ===== MULTIPLE PLANS MODE =====
    elif subpage == "–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É—Å–ª—É–≥ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤":
        st.subheader("–ù–µ—Å–∫–æ–ª—å–∫–æ —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤")
        
        locale_gen = st.text_input("Language", value="en-US")
        file = st.file_uploader("Excel —Ñ–∞–π–ª (4 –∫–æ–ª–æ–Ω–∫–∏)", type=["xls", "xlsx"])
        
        st.info("Excel –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 4 –∫–æ–ª–æ–Ω–∫–∏: –ò–º—è JSON | ID JSON | ID —É—Å–ª—É–≥–∏ | –ù–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏")
        
        if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å ZIP", type="primary") and file:
            try:
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞..."):
                    df = pd.read_excel(file, engine="openpyxl")
                
                is_valid, error_msg = validate_excel_columns(df, 4, "multi plan")
                if not is_valid:
                    st.error(error_msg)
                    st.stop()
                
                df_cleaned, duplicates_count = remove_duplicates(df, [0, 1, 2, 3])
                if duplicates_count > 0:
                    st.info(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}")
                
                grouped = df_cleaned.groupby([df_cleaned.columns[0], df_cleaned.columns[1]])
                
                zip_buffer = io.BytesIO()
                json_count = 0
                
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                    for (json_name, json_id), group in grouped:
                        offerings = [
                            create_offering(r[df_cleaned.columns[2]], r[df_cleaned.columns[3]], locale_gen)
                            for _, r in group.iterrows()
                            if pd.notna(r[df_cleaned.columns[2]])
                        ]
                        
                        if not offerings:
                            continue
                        
                        final = build_json(str(json_name), str(json_id), locale_gen, offerings, purpose="addOn")
                        pretty_json = json.dumps(final, ensure_ascii=False, indent=4)
                        zf.writestr(f"productOfferingGroup/{safe_name(json_id)}.json", pretty_json)
                        json_count += 1
                
                zip_buffer.seek(0)
                st.success(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {json_count} JSON —Ñ–∞–π–ª–æ–≤")
                
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å ZIP",
                    zip_buffer,
                    "services_jsons.zip",
                    "application/zip",
                    type="primary"
                )
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")
                with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                    st.exception(e)

    # ===== SWAP OFFER MODE =====
    elif subpage == "Swap Offer (–ø–µ—Ä–µ—Ö–æ–¥—ã —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤)":
        st.subheader("–ü–µ—Ä–µ—Ö–æ–¥—ã —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤")
        
        col1, col2 = st.columns(2)
        with col1:
            name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ swap offer")
            uid = st.text_input("ID swap offer")
        with col2:
            locale_gen = st.text_input("Language", value="en-US")
        
        file = st.file_uploader("Excel —Ñ–∞–π–ª (1 –∫–æ–ª–æ–Ω–∫–∞: ID —Ç–∞—Ä–∏—Ñ–æ–≤)", type=["xls", "xlsx"])
        
        st.info("Excel –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 1 –∫–æ–ª–æ–Ω–∫—É: ID —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤")
        
        if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å", type="primary") and file:
            try:
                with st.spinner("–ß—Ç–µ–Ω–∏–µ Excel —Ñ–∞–π–ª–∞..."):
                    df = pd.read_excel(file, engine="openpyxl")
                
                is_valid, error_msg = validate_excel_columns(df, 1, "swap offer")
                if not is_valid:
                    st.error(error_msg)
                    st.stop()
                
                df_cleaned, duplicates_count = remove_duplicates(df, [0])
                if duplicates_count > 0:
                    st.info(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}")
                
                id_col = df_cleaned.columns[0]
                offerings = [
                    create_offering(str(r[id_col]).strip())
                    for _, r in df_cleaned.iterrows()
                    if pd.notna(r[id_col])
                ]
                
                if not offerings:
                    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–∞—Ä–∏—Ñ–æ–≤ –≤ Excel —Ñ–∞–π–ª–µ")
                    st.stop()

                if not name.strip() or not uid.strip():
                    st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ '–ù–∞–∑–≤–∞–Ω–∏–µ swap offer' –∏ 'ID swap offer' –¥–ª—è JSON.")
                    st.stop()
                
                final = build_json(name, uid, locale_gen, offerings, purpose="replaceOffer")
                
                st.success(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(offerings)} —Ç–∞—Ä–∏—Ñ–Ω—ã—Ö –ø–ª–∞–Ω–æ–≤")
                with st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä JSON"):
                    st.json(final)
                
                zip_buffer = create_zip_buffer(final, uid)
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å ZIP",
                    zip_buffer,
                    f"{safe_name(name)}.zip",
                    "application/zip",
                    type="primary"
                )
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")
                with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                    st.exception(e)

    # ===== CATEGORY MODE =====
    elif subpage == "–ò–∑–º–µ–Ω–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ProductOfferingCategory":
        st.subheader("–ò–∑–º–µ–Ω–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ProductOfferingCategory")
        
        file = st.file_uploader("Excel —Ñ–∞–π–ª (2 –∫–æ–ª–æ–Ω–∫–∏: Offer_id, Category_id)", type=["xls", "xlsx"])
        
        st.info("Excel –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2 –∫–æ–ª–æ–Ω–∫–∏: Offer_id | Category_id")
        
        with st.expander("–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON"):
            st.code('''{
    "id": "0a9e12ee-4cbf-47aa-a492-82596254721c",
    "category": [
        "39d54e58-67e0-4a0d-89ae-80a6b91ffe17"
    ],
    "categoryRef": [
        {
            "id": "39d54e58-67e0-4a0d-89ae-80a6b91ffe17"
        }
    ]
}''', language="json")
        
        if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å ZIP", type="primary") and file:
            try:
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞..."):
                    df = pd.read_excel(file, engine="openpyxl")
                
                is_valid, error_msg = validate_excel_columns(df, 2, "category")
                if not is_valid:
                    st.error(error_msg)
                    st.stop()
                
                df_cleaned, duplicates_count = remove_duplicates(df, [0, 1])
                if duplicates_count > 0:
                    st.info(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}")
                
                offer_col, category_col = df_cleaned.columns[0], df_cleaned.columns[1]
                grouped = df_cleaned.groupby(offer_col)
                
                zip_buffer = io.BytesIO()
                json_count = 0
                
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
                    for offer_id, group in grouped:
                        if pd.isna(offer_id):
                            continue
                        
                        categories = [
                            str(r[category_col]).strip()
                            for _, r in group.iterrows()
                            if pd.notna(r[category_col])
                        ]
                        
                        if not categories:
                            continue
                        
                        category_json = {
                            "id": str(offer_id).strip(),
                            "category": categories,
                            "categoryRef": [{"id": cat_id} for cat_id in categories]
                        }
                        
                        pretty_json = json.dumps(category_json, ensure_ascii=False, indent=4)
                        zf.writestr(f"productOfferingCategory/{safe_name(offer_id)}.json", pretty_json)
                        json_count += 1
                
                zip_buffer.seek(0)
                st.success(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {json_count} JSON —Ñ–∞–π–ª–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
                
                if json_count > 0:
                    df_preview = df_cleaned.head(3)
                    with st.expander("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                        st.dataframe(df_preview)
                
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å ZIP",
                    zip_buffer,
                    "product_offering_categories.zip",
                    "application/zip",
                    type="primary"
                )
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞: {e}")
                with st.expander("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏"):
                    st.exception(e)
